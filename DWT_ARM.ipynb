{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 140)\n",
      "(1, 140)\n",
      "(140,)\n",
      "(140,)\n",
      "(1152, 3, 140)\n",
      "(140, 2, 448)\n",
      "(140, 2, 448)\n"
     ]
    }
   ],
   "source": [
    "#load_data\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import mne\n",
    "from scipy import signal\n",
    "data=scipy.io.loadmat('dataset_BCIcomp1.mat')\n",
    "data_test=data['x_test']\n",
    "data_train=data['x_train']\n",
    "label_train=data['y_train'].reshape(1,-1)-1\n",
    "label=scipy.io.loadmat('y_test.mat')\n",
    "label_test=label['y_test'].reshape(1,-1)-1\n",
    "print(label_test.shape)\n",
    "print(label_train.shape)\n",
    "y_train=label_train[0]\n",
    "y_test=label_test[0]\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "b,a=signal.butter(8,[(16/128),(64/128)],'bandpass')\n",
    "buffer_x_test=signal.filtfilt(b,a,data_test,axis=0)\n",
    "buffer_x_train=signal.filtfilt(b,a,data_train,axis=0)\n",
    "print(buffer_x_test.shape)\n",
    "all_x_train=np.transpose(buffer_x_train,[2,1,0])\n",
    "all_x_test=np.transpose(buffer_x_test,[2,1,0])\n",
    "x_train=all_x_train[:,0::2,448:896]\n",
    "print(x_train.shape)\n",
    "x_test=all_x_test[:,0::2,448:896]\n",
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117,)\n",
      "(62,)\n",
      "(227,)\n",
      "(62,)\n",
      "(140, 2, 448)\n",
      "(140, 2, 448)\n",
      "(140, 2, 448)\n",
      "(140, 2, 448)\n"
     ]
    }
   ],
   "source": [
    "#decompose and reconstruct EEG signals\n",
    "import pywt\n",
    "db4=pywt.Wavelet('db4')\n",
    "cA3,cD3,cD2,cD1= pywt.wavedec(x_train[1,1,:],db4,mode='symmetric',level=3)\n",
    "print(cD2.shape)\n",
    "print(cA3.shape)\n",
    "print(cD1.shape)\n",
    "print(cD3.shape)\n",
    "cD2=np.zeros(117)\n",
    "cA3=np.zeros(62)\n",
    "cD1=np.zeros(227)\n",
    "x_zz3=pywt.waverec([cA3,cD3,cD2,cD1],db4)\n",
    "import pywt\n",
    "db4=pywt.Wavelet('db4')\n",
    "def Dwt(X):\n",
    "    cA3,cD3,cD2,cD1 = pywt.wavedec(X,db4,mode='symmetric',level=3)\n",
    "    return cA3,cD3,cD2,cD1\n",
    "def cD3_features(x):\n",
    "    Bands_D3=np.empty((x.shape[0],x.shape[1],448))\n",
    "    for i in range(x.shape[0]):\n",
    "        for ii in range(x.shape[1]):\n",
    "            cA3,cD3,cD2,cD1=Dwt(x[i,ii,:])\n",
    "            cA3=np.zeros(62)\n",
    "            cD2=np.zeros(117)\n",
    "            cD1=np.zeros(227)\n",
    "            Bands_D3[i,ii,:]=pywt.waverec([cA3,cD3,cD2,cD1],db4)\n",
    "    return Bands_D3\n",
    "def cD2_features(x):\n",
    "    Bands_D2=np.empty((x.shape[0],x.shape[1],448))\n",
    "    for i in range(x.shape[0]):\n",
    "        for ii in range(x.shape[1]):\n",
    "            cA3,cD3,cD2,cD1=Dwt(x[i,ii,:])\n",
    "            cA3=np.zeros(62)\n",
    "            cD3=np.zeros(62)\n",
    "            cD1=np.zeros(227)\n",
    "            Bands_D2[i,ii,:]=pywt.waverec([cA3,cD3,cD2,cD1],db4)\n",
    "    return Bands_D2\n",
    "x_train_d3=cD3_features(x_train)\n",
    "x_train_d2=cD2_features(x_train)\n",
    "x_test_d3=cD3_features(x_test)\n",
    "x_test_d2=cD2_features(x_test)\n",
    "print(x_train_d3.shape)\n",
    "print(x_test_d3.shape)\n",
    "print(x_train_d2.shape)\n",
    "print(x_test_d2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in c:\\users\\medha\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (0.11.1)\n",
      "Requirement already satisfied: numpy>=1.14 in c:\\users\\medha\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from statsmodels) (1.18.4)\n",
      "Requirement already satisfied: patsy>=0.5 in c:\\users\\medha\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from statsmodels) (0.5.1)\n",
      "Requirement already satisfied: pandas>=0.21 in c:\\users\\medha\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from statsmodels) (1.0.3)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\medha\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from statsmodels) (1.4.1)\n",
      "Requirement already satisfied: six in c:\\users\\medha\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from patsy>=0.5->statsmodels) (1.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\medha\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from pandas>=0.21->statsmodels) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\medha\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from pandas>=0.21->statsmodels) (2020.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcutue AR coef of each  channel in EEG signals of different frequency bands\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "def get_ARcoef(x):\n",
    "    model=AR(x)\n",
    "    model_fit=model.fit(maxlag=5)\n",
    "    coef=model_fit.params\n",
    "    return coef\n",
    "def get_features(x,y):\n",
    "    for i in range(140):\n",
    "        for j in range(2):\n",
    "            y[i,j]=get_ARcoef(x[i,j])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\medha\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\statsmodels\\tsa\\ar_model.py:691: FutureWarning: \n",
      "statsmodels.tsa.AR has been deprecated in favor of statsmodels.tsa.AutoReg and\n",
      "statsmodels.tsa.SARIMAX.\n",
      "\n",
      "AutoReg adds the ability to specify exogenous variables, include time trends,\n",
      "and add seasonal dummies. The AutoReg API differs from AR since the model is\n",
      "treated as immutable, and so the entire specification including the lag\n",
      "length must be specified when creating the model. This change is too\n",
      "substantial to incorporate into the existing AR api. The function\n",
      "ar_select_order performs lag length selection for AutoReg models.\n",
      "\n",
      "AutoReg only estimates parameters using conditional MLE (OLS). Use SARIMAX to\n",
      "estimate ARX and related models using full MLE via the Kalman Filter.\n",
      "\n",
      "To silence this warning and continue using AR until it is removed, use:\n",
      "\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore', 'statsmodels.tsa.ar_model.AR', FutureWarning)\n",
      "\n",
      "  warnings.warn(AR_DEPRECATION_WARN, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 2, 6)\n",
      "[[[ 1.96683954e-05  1.58759914e+00 -1.11957103e+00  4.59665393e-01\n",
      "   -3.82018887e-01  1.17173806e-01]\n",
      "  [ 4.08353474e-05  1.48225280e+00 -9.03157835e-01  2.83093576e-01\n",
      "   -4.18375501e-01  2.50162312e-01]]\n",
      "\n",
      " [[-7.98295629e-05  1.63455534e+00 -1.18856285e+00  5.18766688e-01\n",
      "   -3.84802769e-01  9.91864183e-02]\n",
      "  [ 1.80103329e-05  1.69647431e+00 -1.25681767e+00  5.66221989e-01\n",
      "   -3.78360584e-01  8.72372463e-02]]\n",
      "\n",
      " [[-6.76698512e-05  1.61662872e+00 -1.15397453e+00  4.83491408e-01\n",
      "   -3.79288143e-01  1.11062174e-01]\n",
      "  [-5.67337718e-05  1.60407548e+00 -1.06896089e+00  3.77826494e-01\n",
      "   -3.64049489e-01  1.73162168e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-4.61211296e-05  1.64852091e+00 -1.18256573e+00  4.95813617e-01\n",
      "   -3.72096087e-01  1.10573550e-01]\n",
      "  [-4.93583614e-05  1.70519528e+00 -1.30129908e+00  6.31858330e-01\n",
      "   -3.99846770e-01  6.71370801e-02]]\n",
      "\n",
      " [[ 2.45310797e-05  1.68419427e+00 -1.25819491e+00  5.81020249e-01\n",
      "   -3.87111966e-01  7.98037081e-02]\n",
      "  [ 1.95238822e-05  1.71360453e+00 -1.30543531e+00  6.32273006e-01\n",
      "   -3.98954051e-01  6.90948030e-02]]\n",
      "\n",
      " [[-6.13699614e-05  1.67937822e+00 -1.27767052e+00  6.24305126e-01\n",
      "   -4.04630088e-01  6.38586541e-02]\n",
      "  [-3.14056580e-05  1.64723391e+00 -1.14841273e+00  4.46216317e-01\n",
      "   -3.56864119e-01  1.31622929e-01]]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d3_train_features=pd.DataFrame(X_train)\n",
    "d3_train_features.to_csv('features.csv')\n",
    "d3_train_coef=np.zeros((140,2,6))\n",
    "d3_test_coef=np.zeros((140,2,6))\n",
    "d2_train_coef=np.zeros((140,2,6))\n",
    "d2_test_coef=np.zeros((140,2,6))\n",
    "d3_train_features=get_features(x_train_d3,d3_train_coef)\n",
    "d2_train_features=get_features(x_train_d2,d2_train_coef)\n",
    "d3_test_features=get_features(x_test_d3,d3_test_coef)\n",
    "d2_test_features=get_features(x_test_d2,d2_test_coef)\n",
    "print(d3_train_features.shape)\n",
    "print(d3_train_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 24)\n",
      "(140, 24)\n",
      "[[ 0.36055183 -0.520549    0.28248871 ...  0.90562401 -0.05478024\n",
      "  -0.29748046]\n",
      " [-1.35625364  0.2382766  -0.27809691 ...  1.01998547 -1.8060067\n",
      "   1.6353143 ]\n",
      " [-1.1464417  -0.05142263  0.00294678 ...  0.19150651  0.12655755\n",
      "  -0.36901726]\n",
      " ...\n",
      " [-0.7746254   0.46396425 -0.22936797 ...  0.87649892 -1.17139276\n",
      "   0.97761816]\n",
      " [ 0.4444559   1.04045591 -0.84388477 ...  0.87443441  0.17844861\n",
      "  -0.80602261]\n",
      " [-1.03773912  0.96262712 -1.00213177 ... -1.43234994  0.45259185\n",
      "  -0.17353459]]\n",
      "[[ 0.27193525 -3.20229248  2.89871703 ... -0.4130415   1.04733446\n",
      "  -1.05252966]\n",
      " [-0.51568197 -1.08754206  1.22688352 ...  0.31634495 -0.07345964\n",
      "  -0.21373256]\n",
      " [-1.06452569  0.66150511 -0.49528924 ...  0.8019574  -0.88537507\n",
      "   0.8575252 ]\n",
      " ...\n",
      " [-1.19796409  0.75175089 -0.76834107 ... -0.34577342  0.40495993\n",
      "  -0.41171417]\n",
      " [ 0.47244712  0.57474256 -0.80423205 ... -0.02603259  0.22917936\n",
      "  -0.1977518 ]\n",
      " [-0.12774406  0.49144038 -0.63167836 ...  0.45496229 -0.56287791\n",
      "   0.63094661]]\n"
     ]
    }
   ],
   "source": [
    "#concatenate and normalize the coef as extracted features\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc=[]\n",
    "ss = preprocessing.StandardScaler()\n",
    "X_train=ss.fit_transform(np.concatenate((d3_train_features[:,0,:],d3_train_features[:,1,:],d2_train_features[:,0,:],d2_train_features[:,1,:]),axis=1))\n",
    "X_test=ss.transform(np.concatenate((d3_test_features[:,0,:],d3_test_features[:,1,:],d2_test_features[:,0,:],d2_test_features[:,1,:]),axis=1))\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train)\n",
    "print(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
